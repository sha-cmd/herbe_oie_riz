{
  
    
        "post0": {
            "title": "Quelques Observations Quotidiennes",
            "content": "2021-02-22 . La vision de Copenhague, qui situe le monde quantique dans un autre monde que le monde classique, serait parfait si nous ne voulions pas voir du monde quantique autre chose qu’une vision théorique et mathématique. C’est un monde où les particules se comportent en théorie comme une onde, car rien n’interfère avec leur état. Elles peuvent ainsi être en état de superposition mais sans que nous puissions procéder à une mesure d’une interférence. . Toutefois si nous considérons que la particule est en même temps de nature ondulatoire et corpusculaire, nous obtenons dans ce cas, une vision du monde quantique telle que la décrivent Louis de Broglie et David Bohm et qui s’oppose à la vision de Copenhague. Pour faire simple, l’onde est perçue comme une trame sur laquelle se déplace le corps, un peu comme un surfeur. Mais pour que l’onde agisse sur la particule en permanence et de manière instantanée, quelque-soit la distance entre elles, la transmission devrait se produire à une vitesse supérieure à celle de la lumière, ce qui n’est pas concevable depuis la théorie de la relativité d’Einstein. . Enfin, il peut-être plus intéressant encore de diviser l’univers étudié en autant d’états possibles que peuvent prendre ses particules. En dépliant cette arborescence, nous nous rendons compte qu’il s’agit de duplication de l’univers, un pour chaque état des particules. Le nombre de branches pourra donner le vertige quand les états des particules ne seront pas simplement binaires. . 2021-02-06 . Le grand dilemme de cet avenir vers 2030, de ce futur que nous imaginons infructueux quand nous sommes pessimistes, est dans ce qui représente la prochaine révolution, la physique quantique. Imaginons un seul instant que l’ensemble des positions des électrons dans notre tête soient mesurées par une puce dans notre cerveau relié à un ordinateur quantique par le réseau des réseaux, sans doute dès lors, sera-t-il possible, pour un programme quantique, de deviner nos pensées des minutes qui suivent la mesure. La notion de libre arbitre risque de devenir flou. La fonction d’onde de Schrödinger montre déjà comment se comporte un électron dans son nuage électronique : . $ih frac{ delta psi}{ delta t} = - frac{h^2}{2m} nabla^2 psi+V psi$ . h est une constante, $ psi$ est la fonction d’onde (probabilité de trouvé un électron dans un nuage), V est la description des forces que subit l’électron, et le reste (i, $ frac{ delta}{ delta t}$, $ nabla$ dit nabla) sont des outils mathématiques. Les prédictions seront sans doute plus facile grâce aux ordinateurs quantiques, mais à quel prix pour la liberté de penser ? Les gens seront-ils rangés par paquets bien homogènes ? . 2021-02-02 . Hier je vous parlais d’une idée qui m’avait semblé intéressante, pourquoi, parce que c’est dans l’air du temps et dans mon tempérement également. Mais je sens que je ne suis pas allé assez loin pour atteindre le but que je m’étais fixé qui était celui de dégager mes impressions sur le sujet, donc j’ai trouvé heureusement, ce matin sagement, une énième barrière technologique. Bien que cela bride un peu l’imaginaire, je vais quand même l’évoquer en entrant immédiatement dans le vif du sujet. . C’est tout simplement la perte d’information entre les signaux digitaux et analogiques. La clé de ce sujet est la compression de l’information contenue dans le signal. Il aurait pu sembler regrettable pour un certain ingénieur du son de ma connaissance d’écouter une musique sur un mp3, et pour lui, de plus, il aurait toujours mieux valu un format moins compressé tel que le flac (bien que d’autres formats existent). Mais la vérité c’est que le format mp3 satisfait la majeur parti du public. . Sans doute parce que l’appréciation de la musique ainsi que son interprétation et son réglage n’ont pas la même valeur selon qu’une personne écoute la musique par le ventre ou bien comme une collection de paramètres. L’enjeu de la qualité et de la quantité peut faire débat longtemps, je crois, malheureusement. Qu’en est-il des compositeurs qui entendent les instruments dans leur tête ? Une puce pourrait-elle remplacer cette fonction judicieusement dans leur cerveau ? . 2021-02-01 . La journée commence toujours à la fin lorsque je dois reprendre mes notes pour vous écrire un compte-rendu. Cette fois, j’ai pensé aux puces intégrées dans le cerveau, celles-là mêmes qui pourraient transformer tout novice de la finance en Warren Buffet par une seule opération, certe un peu invasive, mais vous n’aurez rien sans rien. . À quoi bon rêver de ces puces, et surtout, pourrons-nous réellement penser de la même manière une fois qu’elles nous seront implantées ? Une puce ayanc une certaine fréquence d’horloge, alors que le flux de la pensée est irrégulier. Devrons-nous par conséquent apprendre à penser en écoutant un métronome, sans que ça soit un danger majeur pour notre comportement humain. . Les risques seront-ils minimes ou élevés, et pourrons-nous continuer toutes nos activités habituelles ? Tandis que les puces pourraient permettre aux anciens de devenir aussi malin que les petits nouveaux ou en sens contraire, en tout cas, la rotation de la Terre ne s’arrêtera pas de tourner pour si peu… . 2021-01-31 . Encore un autre jour de la période Covid-19 passée dans mon château-fort. En ayant passé des heures à chercher la cause de mon problème pour trouver le remède qui n’était rien de plus que de faire sans faire. Aimer l’eau, l’air, haïr la haine, voilà un résumé de ce petit manuel du terrien. . 2021-01-30 . Les aiguilles ont fait un tour de cadran et je goutte une nouvelle liberté d’action pour organiser un nouveau projet professionnel, après la restructuration de mon service pro, j’entre dans une période de recherche d’une nouvelle entreprise pour un poste à l’identique. Je suis confiant car je ne suis pas le seul à dire que la Data Science et l’IA sont des domaines qui ont un avenir, mais, je l’espère pour moi, aussi en France ! Car malgré les autres grandes puissances et la diversification du hardware qui ira en augmentant (tel que nous pouvons l’imaginer), nous avons des Grands Groupes, et une French Tech avec ses startups ou même ses licornes. . 2021-01-29 . Demain j’aurai sans doute terminé mon travail sur les outils statistiques que je m’étais fixé le mois dernier. Connaître bientôt la satisfaction du travail accompli me permet de garder espoir dans le futur tout en pensant à autre chose qu’au stress hydrique que connaissent déjà plusieurs villes sur Terre. .",
            "url": "https://blog.rboyrie.info/vie%20priv%C3%A9e/2021/01/29/Daily-Observations.html",
            "relUrl": "/vie%20priv%C3%A9e/2021/01/29/Daily-Observations.html",
            "date": " • Jan 29, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Matrices",
            "content": "Domaine . Les matrices sont des objets mathématiques que l’on regroupe dans l’Algèbre Linéaire. Elles permettent d’exprimer des vecteurs dans des espaces à n dimensions. Un vecteur peut être une position, votre géolocalisation sur la Terre, ou tout simplement une information telle que votre rythme cardiaque ou votre revenu. C’est pour cela que notre monde à 3 dimensions spatiales et extensible peuvant recevoir autant de dimension que nécessaire pour décrire la position d’une position appelé vecteur dans un espace à n dimension. . Op&#233;rateur . Quels sont les opérateurs des matrices : . Le produit scalaire : équivalent d’une projection d’un premier vecteur, sur le second. | Le produit vectoriel : c’est la recherche du vecteur perpendiculaire à un plan formé par deux vecteurs, dont la norme est aussi l’aire de ce plan. | La norme : la racine de la somme des carrés des longueurs d’un vecteur sur chaque direction de l’espace à n dimension. | Le déterminant : c’est une caractéristique quantitative des normes de vecteurs dans un espace à n dimensions. Si n vaut 2 ou 3, c’est l’aire ou le volume. | Le vecteur unitaire : c’est un vecteur colinéaire et de même direction qu’un autre, mais sa norme vaut 1. | Le valeur propre : coefficient d’étirement d’un vecteur propre, d’une application linéaire dans un espace vectoriel. | La vecteur propre : vecteur qui est juste étiré ou raccourci lors d’une transformation linéaire dans un espace vectoriel. | Utilisation de Python pour chaque op&#233;rateur . Pour réaliser nos calculs nous aurons besoin de la bibliothèque numpy afin de construire nos tableaux de valeurs. Pour l’installation dans Jupyter-notebook, nous pouvons utiliser la commande suivante : . !pip install scipy numpy sympy . Chargement des biblioth&#232;ques . import numpy as np from numpy import linalg as LA from numpy.linalg import eig from sympy import * . Produit scalaire . ### Produit scalaire: produit de deux vecteurs f = np.array([1,2,4,6,7]) g = np.array([4,5,3,8,3]) ### 1*4+2*5+4*3+6*8+7*3 np.dot(f, g) . 95 . Dans l’étude du produit vectoriel et de la norme ci-dessous, nous considérons semblables les représentations géométriques et algébriques de vecteurs. Cela nous permet de dire que la norme d’un vecteur h par le produit vectoriel de deux vecteurs f, g est égale à l’aire du plan formé par ces deux derniers vecteurs. . Produit vectoriel . ### Produit vectoriel équivaut au produit extérieur: f x g = f ∧ g f = np.array([3,5,2]) g = np.array([5,7,4]) ### i(5*4-7*2)+j(5*2-3*4)+k(3*7-5*5) np.cross(f, g) . array([ 6, -2, -4]) . Norme . ### Produit vectoriel équivaut au produit extérieur: f x g = f ∧ g soit le vecteur h f = np.array([3,5,2]) g = np.array([5,7,4]) ### i(5*4-7*2)+j(5*2-3*4)+k(3*7-5*5) h = np.cross(f, g) ### La norme de h vaut le produit extérieur f ∧ g LA.norm(h,1) . 12.0 . Le d&#233;terminant . a = np.array(([1,2],[-3,4])) int(np.linalg.det(a)) . 10 . Nous pouvons tout à fait utiliser plutôt le module sympy et faire le calcul comme suivant. . M = Matrix([[1,2],[-3,4]]) M . $ displaystyle left[ begin{matrix}1 &amp; 2 -3 &amp; 4 end{matrix} right]$ M.det() . $ displaystyle 10$ Le vecteur unitaire . Le vecteur unitaire a une magnitude de 1, sa formule est $ hat{v} = frac{1}{ lvert lvert v rvert rvert} cdot v$ . . v = np.arange(3) v_hat = v / np.linalg.norm(v) v_hat . array([0. , 0.4472136 , 0.89442719]) . La valeur propre et le vecteur propre . Dans une application linéaire, un vecteur propre est la transformation linéaire telle celle de la multiplication d’un vecteur par une valeur propre (scalaire). . $T(v)= lambda v$ . En somme, pour une transformation donnée, c’est les vecteurs qui sont sur la ou les ligne(s) de transformation(s) et pour qui tout vecteur se trouvant dessus sera soit étiré soit réduit mais dont la direction ne changera pas. . a = np.array([[2, 0, 0], [0, 3, 4], [0, 4, 9]]) values , vectors = eig(a) print(values) print(vectors) . [11. 1. 2.] [[ 0. 0. 1. ] [ 0.4472136 0.89442719 0. ] [ 0.89442719 -0.4472136 0. ]] . De même, avec le module python sympy, nous pouvons déclarer une matrice M et exécuter les calculs. . M = Matrix([[2, 0, 0], [0, 3, 4], [0, 4, 9]]) M . $ displaystyle left[ begin{matrix}2 &amp; 0 &amp; 0 0 &amp; 3 &amp; 4 0 &amp; 4 &amp; 9 end{matrix} right]$ M.eigenvals() . {11: 1, 2: 1, 1: 1} . M.eigenvects() . [(1, 1, [Matrix([ [ 0], [-2], [ 1]])]), (2, 1, [Matrix([ [1], [0], [0]])]), (11, 1, [Matrix([ [ 0], [1/2], [ 1]])])] . M = Matrix([[2, 4], [3, 13]]) M . $ displaystyle left[ begin{matrix}2 &amp; 4 3 &amp; 13 end{matrix} right]$ M.eigenvals() . {14: 1, 1: 1} .",
            "url": "https://blog.rboyrie.info/math/matrices/2020/12/10/Matrix.html",
            "relUrl": "/math/matrices/2020/12/10/Matrix.html",
            "date": " • Dec 10, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "One-way ANOVA",
            "content": "O&#249; s&#8217;utilise cette m&#233;thode . Nous trouvons cette méthode d’analyse de la variance dans les sciences comme la psychologie, les sciences sociales, les sciences naturelles. Elle permet l’analyse d’une variable indépendante dans plusieurs groupes : un sociologue pourra mesurer le niveau de salaire d’une personne en fonction de son niveau d’étude, un consommateur pourra comparer la consommation moyenne de véhicules suivant le modèle… Pour mesurer plusieurs groupes, les statisticiens ont développé la méthode d’analyse de la variance ou ANOVA. La plus simple, qui analyse une seule variable indépendante est la one-way ANOVA. . Principe . Le but de la méthode one-way ANOVA est de trouver s’il existe une différence statistiquement significative dans les moyennes de plusieurs groupes. La méthode utilise la variance pour vérifier que les moyennes sont semblables. . Hypoth&#232;ses de travail . Chaque échantillon est pris d’une population dont la distribution est considérée comme suivant une loi Normale. | L’échantillonnage est aléatoire, et le tirage de chaque groupe est indépendent. | Les populations des groupes ont un écart type équivalent ou égal. | Le facteur est une variable de catégorie | La réponse est une variable numérique | Test d&#8217;hypoth&#232;se . L’hypothèse nulle est le cas dans lequel toutes les moyennes sont égales. L’hypothèse alternative est qu’au moins un couple de moyennes n’est pas équivalent. . Calcul du test d&#8217;hypoth&#232;se . Pour réaliser le calcul, nous utilisons la distribution F. Cette statistique est un ratio (un rapport, une fraction) comprenant deux degrés de liberté, un pour le numérateur, l’autre pour le dénominateur. . Note :La distribution F dérive du t-test et de la distribution Student, qui est simplement l’élévation au carré de celle-là. Il est préférable d’utiliser la méthode one-way ANOVA quand on veut étudier plusieurs groupes au-lieu que de réaliser de multiple t-test à cause du risque $ alpha$ qui est le rejet de l’hypothèse nulle alors qu’elle est vraie. . Le calcul de Ratio-F . $F = frac{MS_{between}}{MS_{within}}$ La valeur de F est le rapport entre la moyenne de la variance au carré entre les groupes, et la moyenne de la variance au carré dans les groupes (dû à l’échantillonage). . $MS_{between} = frac{SS_{between}}{df_{between}} = frac{SS_{between}}{k - 1}$ avec $k$ comme nombre de groupe . $MS_{within} = frac{SS_{within}}{df_{within}} = frac{SS_{within}}{n-k}$ avec $n$ comme somme de la quantité d’observations pour tous les groupes. . Quand les groupes ont la même taille, la valeur de F revient à : . $F= frac{n cdot {s_{ bar{x}}}^{2}}{s^{2}}$ . Nous détaillerons plus le calcul dans l’exemple suivant. . Importation des modules scientifiques . Pour réaliser nos calculs nous aurons besoin de la bibliothèque scientifique de python scipy et également de numpy pour construire nos tableaux de valeurs. Pour l’installation dans Jupyter-notebook, nous pouvons utiliser la commande suivante : . !pip install scipy numpy . Requirement already satisfied: scipy in c: programdata anaconda3 lib site-packages (1.5.0) Requirement already satisfied: numpy in c: programdata anaconda3 lib site-packages (1.18.5) . Nous importons la méthode pour la méthode one-way ANOVA, la fonction de densité de F et le module numpy . from scipy.stats import f_oneway from scipy.special import fdtrc import numpy as np . Exemple . Nous collectons des données du supermarché du coin afin de réaliser une analyse de la variance sur trois produits : des fruits, des légumes et des pains. Nous collectons nos données de manière aléatoire à partir des rayons de notre supermarché en prenant le prix au kilos de huit produits non contigus dans chacun des rayons. Nous retrouvons nos 3 catégories et les valeurs numériques (prix par kilogramme) comme suivant : . fruits = np.array([1.99, 3.05, 2.60, 1.45, 2.99, 2.91, 2.72, 3.15]) legumes = np.array([1.25, 1.75, 1.40, 1.66, 2.20, 2.70, 3.00, 1.99]) pains = np.array([0.90, 1.25, 1.10, 1.55, 2.20, 3.00, 3.05, 1.05]) . L’hypothèse nulle $H_{0}$ est que les moyennes des prix de ces trois catégories de produit ne sont pas statistiquement différentes de manière significative au vue de notre jeu de données. Nous pourrons prendre une pvalue de 5%, ce qui représente une certitude de 95% quant à notre résultat, en statistique. . Pour les fruits, les légumes, et les pains, nous avons les valeurs statistiques suivantes : . fruits_mean = fruits.mean() fruits_var = fruits.var() fruits_cnt = len(fruits) fruits_stat = &#39;La moyenne des fruits est &#39; + f&#39;{fruits_mean:0.3}&#39; + &#39;, La variance est &#39; + f&#39;{fruits_var:0.2}&#39; + &#39;, Le nombre d’observations est &#39; + f&#39;{fruits_cnt}&#39; fruits_stat . &#39;La moyenne des fruits est 2.61, La variance est 0.31, Le nombre d’observations est 8&#39; . legumes_mean = legumes.mean() legumes_var = legumes.var() legumes_cnt = len(legumes) legumes_stat = &#39;La moyenne des légumes est &#39; + f&#39;{legumes_mean:0.3}&#39; + &#39;, La variance est &#39; + f&#39;{legumes_var:0.2}&#39; + &#39;, Le nombre d’observations est &#39; + str(legumes_cnt) legumes_stat . &#39;La moyenne des légumes est 1.99, La variance est 0.33, Le nombre d’observations est 8&#39; . pains_mean = pains.mean() pains_var = pains.var() pains_cnt = len(pains) pains_stat = &#39;La moyenne des pains est &#39; + f&#39;{pains_mean:0.3}&#39; + &#39;, La variance est &#39; + f&#39;{pains_var:0.2}&#39; + &#39;, Le nombre d’observations est &#39; + str(pains_cnt) pains_stat . &#39;La moyenne des pains est 1.76, La variance est 0.67, Le nombre d’observations est 8&#39; . Estimation du ratio-F, par la distribution Fischer . Pour parvenir à notre résultat, nous ferons plusieurs calculs. . Les degrés de libertés sont (pour n = 24 , k = 3) : . $df_{num} = 3 - 1$ soit 2 . et . $df_{denom} = 24 - 3$ soit 21 . La valeur de F que nous cherchons est $F_{2,21}$ soit dans la table des valeurs de la distribution F : 3.46 . alldata = np.concatenate([[fruits,legumes,pains]]) k = len(alldata) # Nombre de catégories ...2 N = alldata.shape[0] * alldata.shape[1] # Nombre d’observations ...24 n = alldata.shape[1] # Nombre d’observations dans chaque catégorie ...8 . df_num = k - 1 df_denom = N - k . $SS_{between} = frac{ sum{x^2}}{n} - frac{( sum{x})^2}{N}$ . SS_between = (np.array([fruits.sum()**2, legumes.sum()**2, pains.sum()**2]).sum()/n ) - (np.array([fruits.sum(), legumes.sum(), pains.sum()]).sum()**2 /N) . $SS_{tot} = sum{x^2} - frac{( sum{x})^2}{N}$ . SS_tot = (np.array([fruits**2, legumes**2, pains**2]).sum())- (np.array([fruits, legumes, pains]).sum()**2 /24) . $SS_{within} = SS_{tot}- SS_{between}$ . SS_within = SS_tot - SS_between . MS_between = SS_between / df_num . MS_within = (SS_within) / df_denom . F = MS_between / MS_within F . 3.0596582667896874 . $pvalue = P(F&gt; 3.46) = 0.0682$ . pvalue = fdtrc(df_num, df_denom, F) pvalue . 0.06821436223117332 . En conclusion, d’après nos données, nous sommes sûr à 95% que l’hypothèse nulle $H_{0}$ doit-être rejetée. . La même conclusion peut être calculée, plus rapidement, avec la méthode f_oneway() du module scipy. . f_oneway(fruits, legumes, pains) . F_onewayResult(statistic=3.059658266789707, pvalue=0.06821436223117218) . Restituer graphiquement le r&#233;sultat . Pour observer nos résultats et comprendre visuellement le résultat statistique qui indique que les moyennes sont différentes, nous allons importer deux autres modules en Python pour dessiner nos données. . import pandas as pd import matplotlib.pyplot as plt . df = pd.DataFrame(alldata.T, columns=[&#39;Fruits&#39;,&#39;Legumes&#39;,&#39;Pains&#39;]) # Dessiner un graphique de boîte à moustache boxplot = df.boxplot( figsize=(12, 8)) # Sauvegarder vos boîtes à moustaches plt.savefig(&#39;image.png&#39;) . Grâce à ce graphique qui représente en plus, très bien les quartiles, nous pouvons voir que les fruits contiennent une valeur aberrante, un outsider, très loin du reste du paquet de l’échantillon. .",
            "url": "https://blog.rboyrie.info/statistiques/anova/2020/11/12/One-way-ANOVA.html",
            "relUrl": "/statistiques/anova/2020/11/12/One-way-ANOVA.html",
            "date": " • Nov 12, 2020"
        }
        
    
  
    
        ,"post3": {
            "title": "Microsoft Word Example Post",
            "content": "When writing a blog post with Microsoft Word – the filename becomes the title. In this case the file name is “2020-01-01-Microsoft-Word-Example-Post.docx”. . There is minimal support for Word documents in fastpages compared to Jupyter notebooks. Some known limitations: . alt text in Word documents are not yet supported by fastpages, and will break links to images. . | You can only specify front matter for Word documents globally. See the README for more details. . | . For greater control over the content produced from Word documents, you will need to convert Word to markdown files manually. You can follow the steps in this blog post, which walk you through how to use pandoc to do the conversion. Note: If you wish to customize your Word generated blog post in markdown, make sure you delete your Word document from the _word directory so your markdown file doesn’t get overwritten! . If your primary method of writing blog posts is Word documents, and you plan on always manually editing Word generated markdown files, you are probably better off using fast_template instead of fastpages. . The material below is a reproduction of this blog post, and serves as an illustrative example. . Maintaining a healthy open source project can entail a huge amount of toil. Popular projects often have orders of magnitude more users and episodic contributors opening issues and PRs than core maintainers capable of handling these issues. . Consider this graphic prepared by the NumFOCUS foundation showing the number of maintainers for three widely used scientific computing projects: . . We can see that across these three projects, there is a very low ratio maintainers to users. Fixing this problem is not an easy task and likely requires innovative solutions to address the economics as well as tools. . Due to its recent momentum and popularity, Kubeflow suffers from a similar fate as illustrated by the growth of new issues opened: . . Source: “TensorFlow World 2019, Automating Your Developer Workflow With ML” . Coincidentally, while building out end to end machine learning examples for Kubeflow, we built two examples using publicly available GitHub data: GitHub Issue Summarization and Code Search. While these tutorials were useful for demonstrating components of Kubeflow, we realized that we could take this a step further and build concrete data products that reduce toil for maintainers. . This is why we started the project kubeflow/code-intelligence, with the goals of increasing project velocity and health using data driven tools. Below are two projects we are currently experimenting with : . Issue Label Bot: This is a bot that automatically labels GitHub issues using Machine Learning. This bot is a GitHub App that was originally built for Kubeflow but is now also used by several large open source projects. The current version of this bot only applies a very limited set of labels, however we are currently A/B testing new models that allow personalized labels. Here is a blog post discussing this project in more detail. . | Issue Triage GitHub Action: to compliment the Issue Label Bot, we created a GitHub Action that automatically adds / removes Issues to the Kubeflow project board tracking issues needing triage. . | Together these projects allow us to reduce the toil of triaging issues. The GitHub Action makes it much easier for the Kubeflow maintainers to track issues needing triage. With the label bot we have taken the first steps in using ML to replace human intervention. We plan on using features extracted by ML to automate more steps in the triage process to further reduce toil. . Building Solutions with GitHub Actions . One of the premises of Kubeflow is that a barrier to building data driven, ML powered solutions is getting models into production and integrated into a solution. In the case of building models to improve OSS project health, that often means integrating with GitHub where the project is hosted. . We are really excited by GitHub’s newly released feature GitHub Actions because we think it will make integrating ML with GitHub much easier. . For simple scripts, like the issue triage script, GitHub actions make it easy to automate executing the script in response to GitHub events without having to build and host a GitHub app. . To automate adding/removing issues needing triage to a Kanban board we wrote a simple python script that interfaces with GitHub’s GraphQL API to modify issues. . As we continue to iterate on ML Models to further reduce toil, GitHub Actions will make it easy to leverage Kubeflow to put our models into production faster. A number of prebuilt GitHub Actions make it easy to create Kubernetes resources in response to GitHub events. For example, we have created GitHub Actions to launch Argo Workflows. This means once we have a Kubernetes job or workflow to perform inference we can easily integrate the model with GitHub and have the full power of Kubeflow and Kubernetes (eg. GPUs). We expect this will allow us to iterate much faster compared to building and maintaining GitHub Apps. . Call To Action . We have a lot more work to do in order to achieve our goal of reducing the amount of toil involved in maintaining OSS projects. If your interested in helping out here’s a couple of issues to get started: . Help us create reports that pull and visualize key performance indicators (KPI). https://github.com/kubeflow/code-intelligence/issues/71 . We have defined our KPI here: issue #19 | . | Combine repo specific and non-repo specific label predictions: https://github.com/kubeflow/code-intelligence/issues/70 . | . In addition to the aforementioned issues we welcome contributions for these other issues in our repo. .",
            "url": "https://blog.rboyrie.info/2020/01/01/Microsoft-Word-Example-Post.html",
            "relUrl": "/2020/01/01/Microsoft-Word-Example-Post.html",
            "date": " • Jan 1, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://blog.rboyrie.info/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://blog.rboyrie.info/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}